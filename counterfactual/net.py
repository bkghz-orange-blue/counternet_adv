# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03a_net.ipynb (unless otherwise specified).

__all__ = ['LinearBlock', 'MultilayerPerception', 'BaselineModel', 'ConvBlock', 'MultilayerConv', 'CounterfactualModel',
           'AdvCounterfactualModel', 'AdvCounterfactualFramework', 'ConvCounterNet', 'AE', 'VAE']

# Cell

from .import_essentials import *
from .training_module import AdvBiLevelCounterfactualTrainingModule
from .utils import *
from .training_module import *
from pytorch_lightning.callbacks import EarlyStopping

# Comes from 03b_counterfactual_net.ipynb, cell
class LinearBlock(nn.Module):
    def __init__(self, input_dim, out_dim, dropout=0.3):
        super().__init__()
        self.block = nn.Sequential(
            nn.Linear(input_dim, out_dim),
            # nn.BatchNorm1d(num_features=out_dim),
            nn.LeakyReLU(),
            nn.Dropout(dropout),
        )

    def forward(self, x):
        return self.block(x)


class MultilayerPerception(nn.Module):
    def __init__(self, dims=[3, 100, 10]):
        super().__init__()
        layers  = []
        num_blocks = len(dims)
        for i in range(1, num_blocks):
            layers += [
                LinearBlock(dims[i-1], dims[i])
            ]
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)

class BaselineModel(PredictiveTrainingModule):
    def __init__(self, config):
        super().__init__(config)
        assert self.enc_dims[-1] == self.dec_dims[0]
        self.model = nn.Sequential(
            MultilayerPerception(self.enc_dims),
            MultilayerPerception(self.dec_dims),
            nn.Linear(self.dec_dims[-1], 1)
        )

    def model_forward(self, x):
        # x = ([],)
        x, = x
        y_hat = torch.sigmoid(self.model(x))
        return torch.squeeze(y_hat, -1)

# Comes from 03b_counterfactual_net.ipynb, cell

class ConvBlock(nn.Module):
    def __init__(self, input_dim, out_dim, dropout=0.3):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv1d(input_dim, out_dim, kernel_size=3, padding=1),
            nn.BatchNorm1d(num_features=out_dim),
            nn.LeakyReLU(),
        )

    def forward(self, x):
        return self.block(x)

class MultilayerConv(nn.Module):
    def __init__(self, dims=[3, 100, 10]):
        super().__init__()
        layers  = []
        num_blocks = len(dims)
        for i in range(1, num_blocks):
            layers += [
                ConvBlock(dims[i-1], dims[i])
            ]
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)

# Comes from 03b_counterfactual_net.ipynb, cell

class _CounterfactualModel(pl.LightningModule):
    def __init__(self, config):
        super().__init__()
        enc_dims = config['enc_dims'] if 'enc_dims' in config.keys() else []
        dec_dims = config['dec_dims'] if 'dec_dims' in config.keys() else []
        exp_dims = config['exp_dims'] if 'exp_dims' in config.keys() else []

        assert enc_dims[-1] == dec_dims[0], f"(enc_dims[-1]={enc_dims[-1]}) != (exp_dims[0]={dec_dims[0]})"
        assert enc_dims[-1] == exp_dims[0], f"(enc_dims[-1]={enc_dims[-1]}) != (exp_dims[0]={exp_dims[0]})"

        self.encoder_model = MultilayerPerception(enc_dims)
        # predictor
        self.predictor = MultilayerPerception(dec_dims)
        self.pred_linear = nn.Linear(dec_dims[-1], 1)
        # explainer
        exp_dims = [x for x in exp_dims]
        exp_dims[0] = exp_dims[0] + dec_dims[-1]

        self.explainer = nn.Sequential(
            MultilayerPerception(exp_dims),
            nn.Linear(exp_dims[-1], enc_dims[0])
        )

    def latent_vec(self, x):
        z = self.encoder_model(x)
        pred = self.predictor(z)
        return z, pred

    def latent_output(self, z, pred):
        # prediction
        y_hat = self.latent_y_hat_output(pred)
        # counterfactual example
        z_p = torch.cat((z, pred), -1)
        cf = self.explainer(z_p)
        return y_hat, cf

    def latent_y_hat_output(self, pred):
        y_hat = torch.sigmoid(self.pred_linear(pred))
        return torch.squeeze(y_hat, -1)

    def latent_cf_output(self, z_p):
        return self.explainer(z_p)

    def model_forward(self, x):
        z, pred = self.latent_vec(x)
        return self.latent_output(z, pred)

    def forward(self, x):
        # don't use this method unless the `forward` function is needed
        return self.model_forward(x)


class _CounterfactualFramework(pl.LightningModule):
    def __init__(self, config):
        super().__init__()
        enc_dims = config['enc_dims'] if 'enc_dims' in config.keys() else []
        dec_dims = config['dec_dims'] if 'dec_dims' in config.keys() else []
        exp_dims = config['exp_dims'] if 'exp_dims' in config.keys() else []

        assert enc_dims[-1] == dec_dims[0], f"(enc_dims[-1]={enc_dims[-1]}) != (exp_dims[0]={dec_dims[0]})"
        assert enc_dims[-1] == exp_dims[0], f"(enc_dims[-1]={enc_dims[-1]}) != (exp_dims[0]={exp_dims[0]})"

        # predictor
        self.predictor = MultilayerPerception(enc_dims + dec_dims[1:])
        self.pred_linear = nn.Linear(dec_dims[-1], 1)
        # explainer
        # exp_dims = [x for x in exp_dims]
        # exp_dims[0] = exp_dims[0] + dec_dims[-1]

        self.explainer = nn.Sequential(
            MultilayerPerception(enc_dims + exp_dims[1:]),
            nn.Linear(exp_dims[-1], enc_dims[0])
        )

    def latent_vec(self, x):
        pred = self.predictor(x)
        return x, pred

    def latent_output(self, x, pred):
        # prediction
        y_hat = self.latent_y_hat_output(pred)
        # counterfactual example
        cf = self.explainer(x)
        return y_hat, cf

    def latent_y_hat_output(self, pred):
        y_hat = torch.sigmoid(self.pred_linear(pred))
        return torch.squeeze(y_hat, -1)

    def latent_cf_output(self, z_p):
        return self.explainer(z_p)

    def model_forward(self, x):
        z, pred = self.latent_vec(x)
        return self.latent_output(z, pred)

    def forward(self, x):
        # don't use this method unless the `forward` function is needed
        return self.model_forward(x)



class CounterfactualModel(CounterfactualTrainingModule):
    def __init__(self, config):
        super().__init__(config)
        self.model = _CounterfactualModel(config)

    def latent_vec(self, x):
        return self.model.latent_vec(x)

    def latent_output(self, z, pred):
        return self.model.latent_output(z, pred)

    def latent_y_hat_output(self, pred):
        return self.model.latent_y_hat_output(pred)

    def latent_cf_output(self, z_p):
        return self.model.latent_cf_output(z_p)

    def model_forward(self, x):
        return self.model.model_forward(x)

# Comes from 03b_counterfactual_net.ipynb, cell

class AdvCounterfactualModel(AdvBiLevelCounterfactualTrainingModule):
    def __init__(self, config):
        super().__init__(config)
        self.model = _CounterfactualModel(config)
        self.model_dup = _CounterfactualModel(config)
        self.model_dup.load_state_dict(self.model.state_dict())

    def latent_vec(self, x):
        return self.model.latent_vec(x)

    def latent_output(self, z, pred):
        return self.model.latent_output(z, pred)

    def latent_y_hat_output(self, pred):
        return self.model.latent_y_hat_output(pred)

    def latent_cf_output(self, z_p):
        return self.model.latent_cf_output(z_p)

    def model_forward(self, x):
        return self.model.model_forward(x)

class AdvCounterfactualFramework(AdvBiLevelCounterfactualTrainingModule):
    def __init__(self, config):
        super().__init__(config)
        self.model = _CounterfactualFramework(config)
        self.model_dup = _CounterfactualFramework(config)
        self.model_dup.load_state_dict(self.model.state_dict())

    def latent_vec(self, x):
        return self.model.latent_vec(x)

    def latent_output(self, z, pred):
        return self.model.latent_output(z, pred)

    def latent_y_hat_output(self, pred):
        return self.model.latent_y_hat_output(pred)

    def latent_cf_output(self, z_p):
        return self.model.latent_cf_output(z_p)

    def model_forward(self, x):
        return self.model.model_forward(x)

# Comes from 03b_counterfactual_net.ipynb, cell
class ConvCounterNet(CounterfactualTrainingModule):
    def __init__(self, config):
        super().__init__(config)
        assert self.enc_dims[-1] == self.dec_dims[0], f"(enc_dims[-1]={self.enc_dims[-1]}) != (exp_dims[0]={self.dec_dims[0]})"
        assert self.enc_dims[-1] == self.exp_dims[0], f"(enc_dims[-1]={self.enc_dims[-1]}) != (exp_dims[0]={self.enc_dims[0]})"

        self.encoder_model = MultilayerConv(self.enc_dims)
        # predictor
        self.predictor = MultilayerConv(self.dec_dims)
        self.pred_linear = nn.Linear(self.dec_dims[-1], 1)
        # explainer
        exp_dims = [x for x in self.exp_dims]
        exp_dims[0] = self.exp_dims[0] + self.dec_dims[-1]

        self.explainer = nn.Sequential(
            MultilayerPerception(exp_dims),
            nn.Linear(self.exp_dims[-1], self.enc_dims[0])
        )

    def model_forward(self, x):
        x = x.unsqueeze(dim=-1)
        x = self.encoder_model(x)
        # predicted y_hat
        pred = self.predictor(x)
        y_hat = torch.sigmoid(self.pred_linear(pred.squeeze(-1)))
        # counterfactual example
        x = torch.cat((x, pred), 1).squeeze(-1)
        c = self.explainer(x)
        return torch.squeeze(y_hat, -1), c

# Comes from 05a_baseline_algos.ipynb, cell

class AE(BaseModule):
    def __init__(self, configs, encoded_size=5):
        super().__init__(configs)
        input_dim = configs['encoder_dims'][0]
        self.encoder_model = MultilayerPerception([input_dim, 20, 16, 14, 12, encoded_size])
        self.decoder_model = MultilayerPerception([encoded_size, 12, 14, 16, 20, input_dim])

    def forward(self, x):
        z = self.encoded(x)
        x_prime = self.decoder_model(z)
        return x_prime

    def configure_optimizers(self):
        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=self.lr)

    def encoded(self, x):
        return self.encoder_model(x)

    def training_step(self, batch, batch_idx):
        # batch
        x, _ = batch
        # prediction
        x_prime = self(x)

        loss = F.mse_loss(x_prime, x, reduction='mean')

        self.log('train/loss', loss)

        return loss

    def validation_step(self, batch, batch_idx):
        # batch
        x, _ = batch
        # prediction
        x_prime = self(x)

        loss = F.mse_loss(x_prime, x, reduction='mean')

        self.log('val/val_loss', loss)

        return loss

# Comes from 05a_baseline_algos.ipynb, cell
class VAE(pl.LightningModule):
    def __init__(self, input_dims, encoded_size=5):
        super().__init__()
        self.encoder_mean = MultilayerPerception([input_dims + 1, 20, 16, 14, 12, encoded_size])
        self.encoder_var = MultilayerPerception([input_dims + 1, 20, 16, 14, 12, encoded_size])
        self.decoder_mean = MultilayerPerception([encoded_size + 1, 12, 14, 16, 20, input_dims])

    def encoder(self, x):
        mean = self.encoder_mean(x)
        logvar = 0.5+ self.encoder_var(x)
        return mean, logvar

    def decoder(self, z):
        mean = self.decoder_mean(z)
        return mean

    def sample_latent_code(self, mean, logvar):
        eps = torch.randn_like(logvar)
        return mean + torch.sqrt(logvar) * eps

    def normal_likelihood(self, x, mean, logvar, raxis=1):
        return torch.sum( -.5 * ((x - mean)*(1./logvar)*(x-mean) + torch.log(logvar) ), axis=1)

    def forward(self, x, c):
        """
        x: input instance
        c: target y
        """
        c = c.view(c.shape[0], 1)
        c = torch.tensor(c).float()
        res = {}
        mc_samples = 50
        em, ev = self.encoder(torch.cat((x, c), 1))
        res['em'] = em
        res['ev'] = ev
        res['z'] = []
        res['x_pred'] = []
        res['mc_samples'] = mc_samples
        for i in range(mc_samples):
            z = self.sample_latent_code(em, ev)
            x_pred = self.decoder(torch.cat((z, c), 1))
            res['z'].append(z)
            res['x_pred'].append(x_pred)
        return res

    def compute_elbo(self, x, c, model):
        c= c.clone().detach().float()
        c=c.view(c.shape[0], 1)
        em, ev = self.encoder(torch.cat((x,c),1))
        kl_divergence = 0.5*torch.mean(em**2 + ev - torch.log(ev) - 1, axis=1)

        z = self.sample_latent_code(em, ev)
        dm= self.decoder( torch.cat((z,c),1) )
        log_px_z = torch.tensor(0.0)

        x_pred= dm
        return torch.mean(log_px_z), torch.mean(kl_divergence), x, x_pred, model.predict(x_pred)